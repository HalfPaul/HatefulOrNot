{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and cleaning data\n",
    "Here I deleted neutral posts and changed categury's values so that it would be easier for sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you should all sit down together and watch the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...         0\n",
       "4  for your own benefit you may want read living ...         1\n",
       "5  you should all sit down together and watch the...         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Reddit_data.csv')\n",
    "data = data[data.category != 0]\n",
    "data[\"clean_comment\"] = data[\"clean_comment\"].astype(str)\n",
    "data.category = data.category.map({ 1 : 1, -1 : 0})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"clean_comment\"]\n",
    "y = data[\"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "First we decapitalize all words and leave only proper words. Then we turn 5000 words into numeric values and pad texts so they are all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = X.apply(lambda x: x.lower())\n",
    "X = X.apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=5000, split=' ')\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "X = tokenizer.texts_to_sequences(X.values)\n",
    "X = pad_sequences(X, maxlen = 256)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.pickle\", \"wb\") as tok:\n",
    "    pickle.dump(tokenizer, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(5000, 128, input_length = X.shape[1]),\n",
    "    keras.layers.SpatialDropout1D(0.4),\n",
    "    keras.layers.LSTM(128, dropout = 0.2, recurrent_dropout = 0.2),\n",
    "    keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "202/202 [==============================] - 224s 1s/step - loss: 0.5576 - accuracy: 0.7149 - val_loss: 0.3903 - val_accuracy: 0.8349\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 257s 1s/step - loss: 0.3240 - accuracy: 0.8691 - val_loss: 0.3212 - val_accuracy: 0.8654\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 254s 1s/step - loss: 0.2279 - accuracy: 0.9131 - val_loss: 0.3197 - val_accuracy: 0.8724\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 255s 1s/step - loss: 0.1728 - accuracy: 0.9377 - val_loss: 0.3359 - val_accuracy: 0.8649\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 233s 1s/step - loss: 0.1403 - accuracy: 0.9498 - val_loss: 0.4065 - val_accuracy: 0.8657\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 234s 1s/step - loss: 0.1186 - accuracy: 0.9583 - val_loss: 0.3765 - val_accuracy: 0.8715\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 231s 1s/step - loss: 0.1026 - accuracy: 0.9634 - val_loss: 0.4183 - val_accuracy: 0.8709\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 226s 1s/step - loss: 0.0794 - accuracy: 0.9739 - val_loss: 0.4173 - val_accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 221s 1s/step - loss: 0.0650 - accuracy: 0.9765 - val_loss: 0.4347 - val_accuracy: 0.8773\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 222s 1s/step - loss: 0.0509 - accuracy: 0.9835 - val_loss: 0.4749 - val_accuracy: 0.8753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2628499f198>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs = 10, validation_split = 0.33, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 7s 48ms/step - loss: 0.5306 - accuracy: 0.8677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5306383371353149, 0.8676897287368774]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0  192    4 1603]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = [\"I hate this nonsense\"]\n",
    "post = tokenizer.texts_to_sequences(post)\n",
    "post = pad_sequences(post, maxlen=28, dtype='int32', value=0)\n",
    "print(post)\n",
    "prediction = model.predict(post)\n",
    "round(float(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   4 890 662]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post2 = [\"This is super amazing\"]\n",
    "post2 = tokenizer.texts_to_sequences(post2)\n",
    "post2 = pad_sequences(post2, maxlen=28, dtype='int32', value=0)\n",
    "print(post2)\n",
    "prediction2 = model.predict(post2)\n",
    "round(float(prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
