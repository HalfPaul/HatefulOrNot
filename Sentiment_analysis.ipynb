{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and cleaning data\n",
    "Here I deleted neutral posts and changed categury's values so that it would be easier for sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you should all sit down together and watch the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...         0\n",
       "4  for your own benefit you may want read living ...         1\n",
       "5  you should all sit down together and watch the...         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Reddit_data.csv')\n",
    "data = data[data.category != 0]\n",
    "data[\"clean_comment\"] = data[\"clean_comment\"].astype(str)\n",
    "data.category = data.category.map({ 1 : 1, -1 : 0})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"clean_comment\"]\n",
    "y = data[\"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "First we decapitalize all words and leave only proper words. Then we turn 5000 words into numeric values and pad texts so they are all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = X.apply(lambda x: x.lower())\n",
    "X = X.apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=5000, split=' ')\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "X = tokenizer.texts_to_sequences(X.values)\n",
    "X = pad_sequences(X, maxlen = 256)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.pickle\", \"wb\") as tok:\n",
    "    pickle.dump(tokenizer, tok, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(5000, 128, input_length = X.shape[1]),\n",
    "    keras.layers.SpatialDropout1D(0.4),\n",
    "    keras.layers.LSTM(128, dropout = 0.2, recurrent_dropout = 0.2),\n",
    "    keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "202/202 [==============================] - 307s 2s/step - loss: 0.6326 - accuracy: 0.6601 - val_loss: 0.4420 - val_accuracy: 0.8041\n",
      "Epoch 2/15\n",
      "202/202 [==============================] - 313s 2s/step - loss: 0.3433 - accuracy: 0.8618 - val_loss: 0.3626 - val_accuracy: 0.8451\n",
      "Epoch 3/15\n",
      "202/202 [==============================] - 319s 2s/step - loss: 0.2211 - accuracy: 0.9180 - val_loss: 0.3409 - val_accuracy: 0.8588\n",
      "Epoch 4/15\n",
      "202/202 [==============================] - 317s 2s/step - loss: 0.1672 - accuracy: 0.9390 - val_loss: 0.3707 - val_accuracy: 0.8611\n",
      "Epoch 5/15\n",
      "202/202 [==============================] - 327s 2s/step - loss: 0.1428 - accuracy: 0.9490 - val_loss: 0.3968 - val_accuracy: 0.8533\n",
      "Epoch 6/15\n",
      "202/202 [==============================] - 323s 2s/step - loss: 0.1084 - accuracy: 0.9654 - val_loss: 0.4393 - val_accuracy: 0.8624\n",
      "Epoch 7/15\n",
      "202/202 [==============================] - 326s 2s/step - loss: 0.1048 - accuracy: 0.9650 - val_loss: 0.4245 - val_accuracy: 0.8660\n",
      "Epoch 8/15\n",
      "202/202 [==============================] - 336s 2s/step - loss: 0.1019 - accuracy: 0.9644 - val_loss: 0.4351 - val_accuracy: 0.8572\n",
      "Epoch 9/15\n",
      "202/202 [==============================] - 339s 2s/step - loss: 0.0811 - accuracy: 0.9725 - val_loss: 0.4639 - val_accuracy: 0.8672\n",
      "Epoch 10/15\n",
      "202/202 [==============================] - 334s 2s/step - loss: 0.0580 - accuracy: 0.9794 - val_loss: 0.5205 - val_accuracy: 0.8638\n",
      "Epoch 11/15\n",
      "202/202 [==============================] - 338s 2s/step - loss: 0.0517 - accuracy: 0.9838 - val_loss: 0.5163 - val_accuracy: 0.8650\n",
      "Epoch 12/15\n",
      "202/202 [==============================] - 336s 2s/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 0.5049 - val_accuracy: 0.8591\n",
      "Epoch 13/15\n",
      "202/202 [==============================] - 331s 2s/step - loss: 0.0463 - accuracy: 0.9840 - val_loss: 0.6357 - val_accuracy: 0.8639\n",
      "Epoch 14/15\n",
      "202/202 [==============================] - 332s 2s/step - loss: 0.0385 - accuracy: 0.9865 - val_loss: 0.5761 - val_accuracy: 0.8643\n",
      "Epoch 15/15\n",
      "202/202 [==============================] - 330s 2s/step - loss: 0.0412 - accuracy: 0.9858 - val_loss: 0.6001 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f4537f240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs = 15, validation_split = 0.33, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 8s 55ms/step - loss: 0.6008 - accuracy: 0.8681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6007784008979797, 0.8681045174598694]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0  192    4 1603]]\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 28).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = [\"I hate this nonsense\"]\n",
    "post = tokenizer.texts_to_sequences(post)\n",
    "post = pad_sequences(post, maxlen=28, dtype='int32', value=0)\n",
    "print(post)\n",
    "prediction = model.predict(post)\n",
    "round(float(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   4 889 662]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post2 = [\"This is super amazing\"]\n",
    "post2 = tokenizer.texts_to_sequences(post2)\n",
    "post2 = pad_sequences(post2, maxlen=28, dtype='int32', value=0)\n",
    "print(post2)\n",
    "prediction2 = model.predict(post2)\n",
    "round(float(prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
